# services/embedding_service.py (Optimized - Using Gemini)

import os
import numpy as np
import google.generativeai as genai
from typing import List, Union
from config.database_config import db
from dotenv import load_dotenv

load_dotenv()

# ğŸš¨ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ØªØ¬Ù‡ Ù„Ù€ Gemini embeddings
VECTOR_DIMENSION = 768

class EmbeddingService:
    def __init__(self):
        """
        Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini API Ù„Ù„Ù€ embeddings Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† sentence-transformers
        Ø£Ø®Ù ÙˆØ£Ø³Ø±Ø¹ ÙˆØ¨Ø¯ÙˆÙ† Ù…ÙƒØªØ¨Ø§Øª Ø«Ù‚ÙŠÙ„Ø©!
        """
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("âŒ GEMINI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ù„Ù .env")
        
        genai.configure(api_key=api_key)
        self.vector_size = VECTOR_DIMENSION
        self.embedding_dim = self.vector_size
        
        print(f"âœ… Embedding Service initialized (Gemini API, Dim: {self.vector_size})")
    
    def embed_text(self, text: Union[str, List[str]]) -> List[float]:
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ù†ØµÙŠ (Embedding) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini API
        """
        # Ø§Ù„Ø­Ù…Ø§ÙŠØ©: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ÙØ§Ø±Øº
        if not text or (isinstance(text, str) and not text.strip()):
            return [0.0] * self.vector_size
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ string
        if isinstance(text, list):
            text = text[0] if text else ""
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini embedding API
            result = genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document"
            )
            
            embedding = result['embedding']
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ØµØ­ÙŠØ­
            if len(embedding) != self.vector_size:
                # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                if len(embedding) > self.vector_size:
                    embedding = embedding[:self.vector_size]
                else:
                    embedding = embedding + [0.0] * (self.vector_size - len(embedding))
            
            return embedding
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡: {str(e)}")
            print(f"   Ø§Ù„Ù†Øµ: '{text[:50]}...'")
            return [0.0] * self.vector_size
    
    def cosine_similarity(self, vec1: Union[np.ndarray, List[float]], vec2: Union[np.ndarray, List[float]]) -> float:
        """
        Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ÙƒÙˆØ³Ø§ÙŠÙ† Ø¨ÙŠÙ† Ù…ØªØ¬Ù‡ÙŠÙ†
        """
        vec1_np = np.array(vec1) if not isinstance(vec1, np.ndarray) else vec1
        vec2_np = np.array(vec2) if not isinstance(vec2, np.ndarray) else vec2
        
        norm1 = np.linalg.norm(vec1_np)
        norm2 = np.linalg.norm(vec2_np)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = np.dot(vec1_np, vec2_np) / (norm1 * norm2)
        return float(np.clip(similarity, -1.0, 1.0))
    
    def generate_and_save_supervisor_embedding(self, supervisor_data: dict, paper_titles: List[str]):
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ ÙŠÙ…Ø«Ù„ Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ù„Ù„Ù…Ø´Ø±Ù
        """
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ
        text_to_embed = (
            f"Supervisor Name: {supervisor_data.get('Name', '')}. "
            f"Department: {supervisor_data.get('Department', '')}. "
            f"Research Interests: " + " | ".join(paper_titles)
        )
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡
        research_embedding = self.embed_text(text_to_embed)
        
        # Ø§Ù„Ø­ÙØ¸ ÙÙŠ MongoDB
        supervisor_id = supervisor_data.get("_id")
        if supervisor_id and research_embedding and len(research_embedding) == self.vector_size:
            db["Supervisor"].update_one(
                {"_id": supervisor_id},
                {"$set": {"research_embedding": research_embedding, "enriched": True}}
            )
            print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ØªØ¬Ù‡ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ù„Ù„Ù…Ø´Ø±Ù ID: {supervisor_id}")
            return research_embedding
        
        return None

embedding_service = EmbeddingService()