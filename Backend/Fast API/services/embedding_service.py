# services/embedding_service.py

from typing import List, Union
import numpy as np
from sentence_transformers import SentenceTransformer
# ÙŠØ¬Ø¨ ØªÙˆÙÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ù„Ù .env Ø£Ùˆ ÙƒÙ…ØªØºÙŠØ± Ø«Ø§Ø¨Øª
# MODEL_NAME Ù‡Ùˆ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…ÙØªØ±Ø¶ Ù„Ù€ 'paraphrase-multilingual-mpnet-base-v2'
MODEL_NAME = "paraphrase-multilingual-mpnet-base-v2" 

# Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª MongoDB Ù„Ù„Ø­ÙØ¸
from config.database_config import db 
import warnings
import os

# ğŸš¨ Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ğŸš¨
# Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
VECTOR_DIMENSION = 768 

class EmbeddingService:
    def __init__(self):
        self.model_name = MODEL_NAME
        self.vector_size = VECTOR_DIMENSION
        # âœ… Ø§Ù„Ø®Ø§ØµÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ¨Ø­Ø« Ø¹Ù†Ù‡Ø§ Ø³ÙƒØ±ÙŠØ¨Øª reindex_projects.py
        self.embedding_dim = self.vector_size 

        # ğŸ”„ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SentenceTransformer
        # ØªÙ… Ø¯Ù…Ø¬ Ù…Ù†Ø·Ù‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ Ø£Ø±Ø³Ù„ØªÙ‡ Ù…Ø¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª
        print("ğŸš€ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Embedding...")
        
        # ØªØ¹Ø·ÙŠÙ„ ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        warnings.filterwarnings("ignore")
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… 'cpu' Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡ Ù„ØªØ¬Ù†Ø¨ Ù…Ø´ÙƒÙ„Ø§Øª GPU Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©
            self.model = SentenceTransformer(self.model_name, device='cpu') 
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­: {self.model_name} (Dim: {self.vector_size})")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {self.model_name}: {e}")
            self.model = None
        
        warnings.filterwarnings("default")

    
    def embed_text(self, text: Union[str, List[str]]) -> List[float]:
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ù†ØµÙŠ (Embedding) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SentenceTransformer.
        Ø§Ø³ØªØ¨Ø¯Ù„Øª create_text_embedding Ø¨Ù€ embed_text Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡.
        """
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­
        if self.model is None:
            print("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„. ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØ¬Ù‡.")
            return []
            
        # Ø§Ù„Ø­Ù…Ø§ÙŠØ© 1: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ÙØ§Ø±Øº Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡
        if not text or (isinstance(text, str) and not text.strip()):
            # Ø¥Ø±Ø¬Ø§Ø¹ vector ØµÙØ±ÙŠ Ø¨Ù†ÙØ³ Ø§Ù„Ø­Ø¬Ù… (768) Ù„ØªÙ…Ø«ÙŠÙ„ "Ù„Ø§ Ù…Ø¹Ù„ÙˆÙ…Ø©"
            return [0.0] * self.vector_size
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© Ù„Ù€ .encode
        if isinstance(text, str):
            text = [text]

        try:
            # Ù†Ø³ØªØ®Ø¯Ù… convert_to_numpy=True Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø±Ø¹
            embedding_np = self.model.encode(text, convert_to_numpy=True)[0] 
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ØªØ¬Ù‡ Ù„Ù‡ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ØµØ­ÙŠØ­ (768)
            if len(embedding_np) != self.vector_size:
                raise ValueError(f"Ø­Ø¬Ù… Ø§Ù„Ù…ØªØ¬Ù‡ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {len(embedding_np)}ØŒ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {self.vector_size}")

            return embedding_np.tolist()
            
        except Exception as e:
            # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠÙƒØ´Ù Ø³Ø¨Ø¨ Ø§Ù„ÙØ´Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
            print(f"âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ Ù„Ù„Ù†Øµ: '{text[0][:50]}...'")
            print(f"âŒ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£: {type(e).__name__} - Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£: {e}")
            return []

    def cosine_similarity(self, vec1: Union[np.ndarray, List[float]], vec2: Union[np.ndarray, List[float]]) -> float:
        """
        Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ÙƒÙˆØ³Ø§ÙŠÙ† Ø¨ÙŠÙ† Ù…ØªØ¬Ù‡ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NumPy.
        """
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ NumPy arrays
        vec1_np = np.array(vec1) if not isinstance(vec1, np.ndarray) else vec1
        vec2_np = np.array(vec2) if not isinstance(vec2, np.ndarray) else vec2

        norm1 = np.linalg.norm(vec1_np)
        norm2 = np.linalg.norm(vec2_np)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        similarity = np.dot(vec1_np, vec2_np) / (norm1 * norm2)
        return float(np.clip(similarity, -1.0, 1.0)) 

    def generate_and_save_supervisor_embedding(self, supervisor_data: dict, paper_titles: List[str]):
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ ÙŠÙ…Ø«Ù„ Ø§Ù„ØªØ®ØµØµ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ù„Ù„Ù…Ø´Ø±Ù ÙˆØ­ÙØ¸Ù‡ ÙÙŠ ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù…Ø´Ø±Ù (MongoDB).
        """
        # 1. ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ
        text_to_embed = (
            f"Supervisor Name: {supervisor_data.get('Name', '')}. " 
            f"Department: {supervisor_data.get('Department', '')}. " 
            f"Research Interests: " + " | ".join(paper_titles)
        )
        
        # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡
        # âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… embed_text Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† create_text_embedding
        research_embedding = self.embed_text(text_to_embed) 
        
        # 3. Ø§Ù„Ø­ÙØ¸ ÙÙŠ MongoDB
        supervisor_id = supervisor_data.get("_id")
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ØªØ¬Ù‡ ØºÙŠØ± ÙØ§Ø±Øº ÙˆØ£Ù† Ø­Ø¬Ù…Ù‡ ØµØ­ÙŠØ­ (768)
        if supervisor_id and research_embedding and len(research_embedding) == self.vector_size:
            # âš ï¸ ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ù…Ø´Ø±ÙÙŠÙ†ØŒ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡ Ø¥Ù„Ù‰ 'Supervisor'
            # ÙÙŠ database_config.py
            db["Supervisor"].update_one( 
                {"_id": supervisor_id},
                {"$set": {"research_embedding": research_embedding, "enriched": True}} # âœ… Ø¥Ø¶Ø§ÙØ© Ø­Ù‚Ù„ enriched
            )
            print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ØªØ¬Ù‡ Ø§Ù„Ø¨Ø­Ø«ÙŠ Ù„Ù„Ù…Ø´Ø±Ù ID: {supervisor_id}")
            return research_embedding
        
        return None

embedding_service = EmbeddingService()