

import os
import google.generativeai as genai
from typing import List, Dict, Optional
from dotenv import load_dotenv
import json
import asyncio 
import re 
from google.generativeai.types import GenerationConfig 

load_dotenv()

class GeminiService:
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY ุบูุฑ ููุฌูุฏ ูู .env")
        
        genai.configure(api_key=api_key)
        
        self.model = genai.GenerativeModel('gemini-2.5-flash') 
        
    
    
    
    
    async def analyze_idea(self, prompt: str) -> str:
        """ ูุฑุณู ููุฌู ูุชุญููู ุงูููุฑุฉ (ุงููุฑุญูุฉ 1 ุฃู 2) ุฅูู ูููุฐุฌ Gemini. """
        try:
            print("๐ค LLM: ุฌุงุฑู ุชุญููู ุงูููุฑุฉ (Gemini) [JSON Mode]...")
            
            config = GenerationConfig(response_mime_type="application/json")
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                contents=prompt,
                generation_config=config 
            )
            return response.text.strip()
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุชุญููู ููุฑุฉ Gemini: {str(e)}")
            return '{"error": "Failed to generate AI analysis due to service error."}'
            
    
    
    

    def analyze_supervisor_research(self, papers: List[Dict], supervisor_name: str) -> Dict:
        """
        ุชุญููู ุฃุจุญุงุซ ุงููุดุฑู ูุงุณุชุฎุฑุงุฌ: ุงูุงูุชูุงูุงุช ุงูุจุญุซูุฉุ ุงููุฌุงู ุงูุฃูุงุฏูููุ ุงูุชุฎุตุต ุงูุฏููู.
        """
        if not papers:
            return self._fallback_analysis(papers)
        
        papers_text = "\n".join([
            f"- ({p.get('year', 'N/A')}) {p.get('title', 'No Title')}"
            for p in papers[:10]
        ])
        
        prompt = f"""
ุฃูุช ูุญูู ุฃูุงุฏููู ูุชุฎุตุต. ูุฏูู ูุงุฆูุฉ ุจุฃุญุฏุซ ุฃุจุญุงุซ ุงููุดุฑู "{supervisor_name}".

**ุงูุฃุจุญุงุซ:**
{papers_text}

**ุงููุทููุจ:** ุญูู ูุฐู ุงูุฃุจุญุงุซ ูุงุณุชุฎุฑุฌ ุจุตูุบุฉ JSON:
{{
  "research_interests": ["ูุงุฆูุฉ ุจู 5-8 ุงูุชูุงูุงุช ุจุญุซูุฉ ุฏูููุฉ (ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ)"],
  "academic_field": "ุงููุฌุงู ุงูุฃูุงุฏููู ุงูุนุงู (ูุซู: Computer Science, Information Systems)",
  "specialization": "ุงูุชุฎุตุต ุงูุฏููู (ูุซู: Machine Learning, IoT Security)"
}}

ุฃุฌุจ ููุท ุจู JSON ุจุฏูู ุฃู ูุต ุฅุถุงูู.
"""
        
        try:
            config = GenerationConfig(response_mime_type="application/json")
            
            response = self.model.generate_content(
                prompt,
                generation_config=config 
            )
            return self._parse_json_response(response.text, papers) 
                
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุชุญููู ุงููุดุฑู Gemini: {str(e)}")
            return self._fallback_analysis(papers)
            
    
    
    
    
    def _parse_json_response(self, result_text: str, fallback_data: Optional[Dict | List] = None) -> Dict | List:
        """ููุทู ุงุณุชุฎุฑุงุฌ ูุชุญููู JSON ุงูููุญุฏุ ููุชุฑุถ ุฃู ุงููููุฐุฌ ูุนูู ูู JSON Mode."""
        try:
            cleaned_text = result_text.strip()
            return json.loads(cleaned_text)
            
        except Exception as e:
            print(f"โ๏ธ ูุดู ุงุณุชุฎุฑุงุฌ JSON ูู ูุถุน JSON Mode: {str(e)}. ูุญุงููุฉ ุงูุชูุธูู ุงูุงุญุชูุงุทูุฉ...")
            match = re.search(r'(\{.*\}|\[.*\])', cleaned_text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except:
                    pass 
            
            print(f"โ ูุดู ุงูุชูุธูู ุงูุงุญุชูุงุทู. ุงููุฌูุก ูุจูุงูุงุช ุงูุฎุทุฃ.")
            
            if isinstance(fallback_data, list):
                return []
            
            if isinstance(fallback_data, list) and fallback_data: 
                return self._fallback_analysis(fallback_data)
                
            return {}

    def _fallback_analysis(self, papers: List[Dict]) -> Dict:
        """ุชุญููู ุงุญุชูุงุทู ุจุณูุท ุจุฏูู AI (ูุณุชุฎุฏู ููุท ูู ุชุญููู ุงููุดุฑููู)"""
        all_titles = " ".join([p.get("title", "") for p in papers[:5]]).lower()
        
        keywords = []
        common_terms = [
            "machine learning", "deep learning", "security", "network",
            "iot", "ai", "data", "wireless", "cloud", "blockchain"
        ]
        
        for term in common_terms:
            if term in all_titles:
                keywords.append(term.title())
        
        return {
            "research_interests": keywords[:5] if keywords else ["Computer Science"],
            "academic_field": "Computer Science",
            "specialization": keywords[0] if keywords else "General Computing"
        }

    
    
    

    async def get_reranked_recommendations(self, reranking_data: List[Dict], idea_text: str) -> List[Dict]:
        """
        ุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุดุฑููู ูุชูููุฏ ุณุจุจ ุงูุชุฑุดูุญ (Re-ranking).
        """
        print("๐ค LLM: ุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุดุฑููู ูุชูููุฏ ุงูุดุฑุญ [JSON Mode]...")
        
        
        supervisors_data = []
        for item in reranking_data:
            top_matched_papers = [t[:100] for t in item.get("top_matched_papers", [])]
            
            
            supervision_match = item.get("supervision_match_score", 0.0)
            
            supervisors_data.append({
                "id": item.get("id"),
                "Name": item.get("name"),
                "Department": item.get("department"),
                "Initial_Score": f"{item.get('initial_score', 0.0):.4f}", 
                "Similarity_Vector_Score": f"{item.get('semantic_similarity', 0.0):.4f}",
                "Matching_Keywords": item.get("matching_keywords", []),
                "Is_Same_Major": item.get("is_same_major", False),
                "Top_Matched_Papers": top_matched_papers,
                
                "Supervision_Match_Score": f"{supervision_match:.2f}" 
            })
            
        data_str = json.dumps(supervisors_data, indent=2, ensure_ascii=False)
        
        
        prompt = f"""
ุฃูุช ุฎุจูุฑ ูู ุงูุฅุดุฑุงู ุงูุฃูุงุฏููู ูุงูุชุญููู ุงูุฏูุงูู ูููุดุงุฑูุน. ูููุชู ูู **ุฅุนุงุฏุฉ ุชุฑุชูุจ** ูุงุฆูุฉ ุงููุดุฑููู ูุชูููุฏ ุชุจุฑูุฑ ููุตู ูุชุฑุดูุญูู.

**ุจูุงูุงุช ุงููุฏุฎูุงุช:**

* **ููุฑุฉ ุงูุทุงูุจ:** {idea_text}
* **ุงููุดุฑููู ุงููุฑุดุญูู (ุงูุชุฑุชูุจ ุงูุฃููู):**
{data_str}

**ููุงุนุฏ ุงูุนูู CRITICAL RULES:**

1. ยูุฌุจ ุฃู ูููู ุงูุฅุฎุฑุงุฌ ูุตูููุฉ JSON (Array of Objects) ุชุญุชูู ุนูู ุฌููุน ุงููุดุฑููู ุงููุฏุฎููู.
2. ยูู **ุจุฅุนุงุฏุฉ ุชุฑุชูุจ** ุงููุดุฑููู ุฏุงุฎู ุงููุตูููุฉ ูู ุงูุฃูุซุฑ ููุงุกูุฉ ุฅูู ุงูุฃูู ููุงุกูุฉ.
3. ยูุฌุจ ุฃู ุชุญุชูู ูู ูุชูุฌุฉ (ูุงุฆู) ุนูู ุญูููู ุฌุฏูุฏูู ุฅูุฒุงููููู:
ย ย * **reranked_score**: ูููุฉ ุฌุฏูุฏุฉ ุจูู 0.0 ู 1.0 ุชุนูุณ ูุฏู ููุงุกูุฉ ุงููุดุฑู ุจุนุฏ ุงูุชุญููู ุงูููุนู (ูุฌุจ ุฃู ุชููู ูุชูุงููุฉ ูุน ุงูุชุฑุชูุจ ุงูุฌุฏูุฏ).
ย ย * **Justification**: **ุชุจุฑูุฑ ููุฌุฒ ููููู (100-150 ูููุฉ)** ูุฑุจุท ุจุดูู ุตุฑูุญ ุจูู **ููุฑุฉ ุงูุทุงูุจ**ุ ู **ูุฌุงู ุงููุดุฑู (Department)**ุ ู **ุงูุชูุงูุงุชู ุงูุจุญุซูุฉ**.
ย ย ย ย **ูุฌุจ ุฃู ูุดูู ุงูุชุจุฑูุฑ ูุง ููู (ุฅู ูุฌุฏ):**
ย ย ย ย * **ุงูุฏููู ุงูุฅุดุฑุงูู:** ุฐูุฑ ุฅุฐุง ูุงูุช ุฏุฑุฌุฉ `Supervision_Match_Score` ุนุงููุฉ (ุฃุนูู ูู 0.60) ูุฃู ุงููุดุฑู ูุฏูู ุฎุจุฑุฉ ูู ูุดุงุฑูุน ูุดุงุจูุฉ.
ย ย ย ย * **ุงูุฏููู ุงูุจุญุซู:** **ุงุณุชุฎุฏู ุนูุงููู ุงูุจุญูุซ ูู ุญูู `Top_Matched_Papers`** ูุฏููู ุนูู ุงูุชุฎุตุต ุงูุฏููู ูููุดุฑู ููุทุงุจูุชูุง ููููุฑุฉ.

**ุชูุณูู ุงูุฅุฎุฑุงุฌ ุงููุทููุจ (ูุตูููุฉ JSON):**

[
ย ย {{
ย ย ย ย "id": 0, 
ย ย ย ย "Name": "ุงูุงุณู",
ย ย ย ย "reranked_score": 0.95, 
ย ย ย ย "Justification": "ุชุจุฑูุฑ ููุฌุฒ ูุฑุจุท ููุฑุฉ ุงูุทุงูุจ ุจุฃุจุญุงุซ ุงููุดุฑู (100-150 ูููุฉ)"
ย ย }},
ย ย {{
ย ย ย ย // ... ุงููุดุฑู ุงูุซุงูู
ย ย }}
]

**Output ONLY the JSON array. No extra text before or after.**
"""
        
        
        try:
            config = GenerationConfig(response_mime_type="application/json")

            response = await asyncio.to_thread(
                self.model.generate_content,
                contents=prompt,
                generation_config=config 
            )
            return self._parse_json_response(response.text, [])
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู Reranking: {str(e)}")
            return []


    
    
    

    async def analyze_project_duplication(self, data_for_llm: Dict) -> Dict:
        """
        ุชุญููู ูุชุงุฆุฌ RAGุ ุชุญุฏูุฏ ูุฏู ุชูุฑุงุฑ ุงููุดุฑูุนุ ูุฅุนุงุฏุฉ ุชุฑุชูุจู.
        """
        print("๐ค LLM: ุชุญููู ุงูุชูุฑุงุฑ ูุชูููุฏ ุงูุชูุฑูุฑ [JSON Mode]...")
        
        abstract = data_for_llm.get("new_idea_abstract", "ุบูุฑ ูุชููุฑ")
        projects_data = data_for_llm.get("retrieved_projects", [])
        projects_str = json.dumps(projects_data, indent=2, ensure_ascii=False)

        prompt = f"""
ุฃูุช ุฎุจูุฑ ูู ูุดุงุฑูุน ุงูุชุฎุฑุฌ ุงูุฃูุงุฏูููุฉ ูุงูุชุญููู ุงูุฃูุงุฏููู. ูููุชู ูู ุชุญููู ูุฏู ุชูุฑุงุฑ ููุฑุฉ ูุดุฑูุน ุฌุฏูุฏุฉ ููุงุฑูุฉ ุจุงููุดุงุฑูุน ูุงูุฃุจุญุงุซ ุงููุฑุฌุนูุฉ ุงูุณุงุจูุฉ.

**ุงูุจูุงูุงุช ุงูููุฏุฎูุฉ:**
* **ููุฎุต ููุฑุฉ ุงูุทุงูุจ ุงูุฌุฏูุฏุฉ (new_idea_abstract):** {abstract}
* **ุงููุดุงุฑูุน ูุงูุฃุจุญุงุซ ุงูููุณุชุฑุฌุนุฉ (retrieved_projects):** ูุฐู ูู ูุงุฆูุฉ ุงููุดุงุฑูุน ุงูุชู ูุฌุฏ ุฃููุง ุงูุฃูุซุฑ ุชุดุงุจูุงู (ุจูุง ูู ุฐูู ุฏุฑุฌุฉ ุงูุชุดุงุจู score).
{projects_str}

---

**ุงูุชุญููู ุงููุทููุจ:**

1.  **ุญุงูุฉ ุงูุชูุฑุงุฑ (duplication_status):** ูู ุจุชุตููู ุญุงูุฉ ุงูุชูุฑุงุฑ ุฅูู ูุงุญุฏุฉ ูู ุงูุขุชู ุจูุงุกู ุนูู ุฃุนูู ุฏุฑุฌุงุช ุงูุชุดุงุจู:
    * **Direct Overlap:** ุฅุฐุง ูุงู ููุงู ูุดุฑูุน ุฃู ุฃูุซุฑ ูุชุดุงุจู ุฌุฏุงู (Similarity Score > 0.85) ูููุฏู ููุณ ุงูุญู.
    * **Potential Overlap:** ุฅุฐุง ูุงู ุงูุชุดุงุจู ูุชูุณุท (Similarity Score > 0.60).
    * **No direct overlap:** ุฅุฐุง ูุงู ุงูุชุดุงุจู ุถุนููุงู (< 0.60).

2.  **ุชูุฑูุฑ ุงูุชุญููู (analysis_report):** ุชูุฑูุฑ ูููู ููุฌุฒ (50-100 ูููุฉ) ููุถุญ ุฌูุงูุจ ุงูุชุดุงุจู ูุงูุงุฎุชูุงู.

3.  **ุงููุดุงุฑูุน ุงููุนุงุฏ ุชุฑุชูุจูุง (reranked_projects):** 
    - ุฃุนุฏ ุชุฑุชูุจ ุงููุดุงุฑูุน ูู ุงูุฃูุซุฑ ุชุดุงุจูุงู ุฅูู ุงูุฃูู.
    - **CRITICAL: ุงุญุชูุธ ุจุงูู abstract ุงูุฃุตูู ููู ูุดุฑูุน ููุง ูู ุชูุงููุง ุจุฏูู ุฃู ุชุนุฏูู ุฃู ุฅุนุงุฏุฉ ุตูุงุบุฉ ุฃู ุชูุฎูุต.**
    - ูุง ุชุถูู ุฃู ูุตูุต ุฅุถุงููุฉ ุฃู ุชูุณูุฑุงุช ูู ุญูู abstract.
    - ุงุญุชูุธ ุจุฌููุน ุงูููุงุชูุญ ุงูุฃุตููุฉ ุงูุฃุฎุฑู (id, title, year, department, similarity_score).

**ุชูุณูู ุงูุฅุฎุฑุงุฌ ุงููุทููุจ (JSON):**

{{
    "duplication_status": "Direct Overlap" | "Potential Overlap" | "No direct overlap",
    "analysis_report": "ุชูุฑูุฑ ุชุญูููู ููุฌุฒ",
    "reranked_projects": [
        // ููุณ ุงููููู ุงูุฃุตูู ูููุดุงุฑูุน ูุน abstract ุงูุฃุตูู ุบูุฑ ูุนุฏู
    ]
}}

**Output ONLY the JSON object. No extra text.**
"""

        try:
            config = GenerationConfig(response_mime_type="application/json")
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                contents=prompt,
                generation_config=config 
            )
            return self._parse_json_response(response.text, {}) 
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุชุญููู ุงูุชูุฑุงุฑ: {str(e)}")
            return {
                "duplication_status": "Error",
                "analysis_report": "ูุดู ูู ุชุดุบูู ุชุญููู LLMุ ูุฑุฌู ุงูุชุญูู ูู ุงูุงุชุตุงู ุจุงูุฎุฏูุฉ.",
                "reranked_projects": data_for_llm.get("retrieved_projects", [])
            }

gemini_service = GeminiService()