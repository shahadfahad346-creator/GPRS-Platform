from typing import List, Dict, Tuple
import asyncio
import numpy as np 
import datetime 

from bson.objectid import ObjectId 
from math import exp 
from sklearn.metrics.pairwise import cosine_similarity 

from bson.objectid import ObjectId # Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø­Ø§Ø³Ù… Ù„ØªØµØ­ÙŠØ­ Ø®Ø·Ø£ ObjectId
import random # Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø¤Ù‚ØªØ§Ù‹ ÙÙŠ Ø¯Ø§Ù„Ø© Supervision Match Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
from math import exp # Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ø§Ù„Ø£Ø³ÙŠ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¯Ø§Ø«Ø©

from config.database_config import db 
from services.serpapi_service import SerpAPIService as ScholarLookupService 
from services.embedding_service import embedding_service 
from services.gemini_service import gemini_service 
from services.qdrant_service import qdrant_service 


# ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø³Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª
from config.database_config import db 
from services.serpapi_service import SerpAPIService as ScholarLookupService 
from services.embedding_service import embedding_service 
from services.gemini_service import gemini_service 
from services.qdrant_service import qdrant_service 

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
scholar_lookup_service = ScholarLookupService()

# ğŸ’¡ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø­Ø¯Ø§Ø«Ø© (Recency)
RECENCY_FULL_SCORE_WINDOW = 3 # Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªÙØ¹ØªØ¨Ø± ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ø¯Ø§Ø«Ø© Ù…Ù…ØªØ§Ø²Ø© (1.00)
RECENCY_DECAY_RATE = 0.25 # Ù…Ø¹Ø¯Ù„ Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (3 Ø³Ù†ÙˆØ§Øª)
# MAX_SUPERVISOR_LOAD = 5 # ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø«Ø§Ø¨Øª Ø£Ù‚ØµÙ‰ Ø­Ù…Ù„ Ø§Ù„Ù…Ø´Ø±Ù

class SupervisorRecommendation:
    def __init__(self):
        self.supervisors_collection = db["Supervisor"] 
        self.projects_collection = db["Graduation Projects BU"] 
        self.QDRANT_COLLECTION = qdrant_service.supervisors_collection
        self.EMBEDDING_LENGTH = 768


    # -------------------------------------------------------------
    # 1. Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¯Ø§Ø«Ø© (Ù…Ø¹Ø¯Ù„Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© ØµÙŠØº Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„Ø©)
    # -------------------------------------------------------------
    def _calculate_recency_score(self, last_updated_date_str: str) -> float:
        """
        ÙŠØ­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø¯Ø§Ø«Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® Ù†Ø´Ø± Ø°ÙŠ ØµÙ„Ø© Ø£Ùˆ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¹Ø§Ù….
        ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ù„ØªÙ‚Ø¨Ù„ ØµÙŠØº Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù…Ø«Ù„ Ø§Ù„Ø³Ù†Ø© ÙÙ‚Ø·).
        """
        if not last_updated_date_str or last_updated_date_str.lower() == 'n/a':
            return 0.00
        
        latest_date = None
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ (YYYY-MM-DD)
            latest_date = datetime.datetime.strptime(last_updated_date_str, "%Y-%m-%d") 
        except ValueError:
            try:
                # ğŸ’¡ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù† Ø§Ù„Ø³Ù†Ø© ÙÙ‚Ø·
                year = int(last_updated_date_str.split('-')[0])
                if year < 1900 or year > datetime.datetime.now().year + 1:
                     return 0.00 
                latest_date = datetime.datetime(year, 1, 1) # Ø¥Ø¶Ø§ÙØ© Ø´Ù‡Ø± ÙˆÙŠÙˆÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠÙŠÙ†
            except Exception:
                return 0.00 
            
        today = datetime.datetime.now()
        years_since_last_update = (today - latest_date).days / 365.25
        
        if years_since_last_update <= RECENCY_FULL_SCORE_WINDOW:
            recency_score = 1.00
        else:
            years_to_decay = years_since_last_update - RECENCY_FULL_SCORE_WINDOW
            recency_score = exp(-RECENCY_DECAY_RATE * years_to_decay)
        
        return round(min(1.00, recency_score), 2)
    # -------------------------------------------------------------


    # -------------------------------------------------------------
    # 2. ğŸ† Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    # -------------------------------------------------------------
    async def _calculate_supervision_match(
        self,
        supervisor_id: str,
        idea_embedding: List[float] 
    ) -> Tuple[float, Dict]: 
        """
        ÙŠØ­Ø³Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø¨ÙŠÙ† ÙÙƒØ±Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø´Ø±Ù 
        ÙˆÙŠØ­Ø¯Ø¯ Ø£ÙØ¶Ù„ Ù…Ø´Ø±ÙˆØ¹ Ù…Ø·Ø§Ø¨Ù‚ ÙƒØ¯Ù„ÙŠÙ„ Ù„Ø¯Ù…Ø¬Ù‡ ÙÙŠ Ø§Ù„ØªØ¨Ø±ÙŠØ±.
        """
        
        try:
            supervisor_doc = self.supervisors_collection.find_one(
                {"_id": ObjectId(supervisor_id)}, 
                {"Name": 1} 
            )
        except Exception:
            return 0.0, {} 
            
        supervisor_name = supervisor_doc.get("Name") if supervisor_doc else None
        
        if not supervisor_name:
            return 0.0, {} 
            
        # 2. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„ØªÙŠ Ø£Ø´Ø±Ù Ø¹Ù„ÙŠÙ‡Ø§
        projects = list(
            self.projects_collection.find(
                {"supervisors": supervisor_name},
                {"embedding": 1, "title": 1, "keywords": 1} 
            )
        )
        
        if not projects:
            return 0.0, {} 
        
        # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        project_embeddings = []
        comparable_projects = [] 
        for project in projects:
            embedding = project.get("embedding")
            if embedding and len(embedding) == self.EMBEDDING_LENGTH: 
                project_embeddings.append(embedding)
                comparable_projects.append(project) 
                
        if not project_embeddings:
            return 0.0, {} 
            
        # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙØ¶Ù„
        try:
            idea_np = np.array(idea_embedding).reshape(1, -1)
            projects_np = np.array(project_embeddings)
            
            similarities = cosine_similarity(idea_np, projects_np)[0] 
            avg_similarity = np.mean(similarities)
            
            best_match_index = np.argmax(similarities)
            best_project = comparable_projects[best_match_index]
            
            best_project_score = float(similarities[best_match_index])
            best_project_info = {
                "title": best_project.get("title", "Ø¹Ù†ÙˆØ§Ù† ØºÙŠØ± Ù…ØªÙˆÙØ±"),
                "keywords": best_project.get("keywords", "ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©"),
                "match_score": round(best_project_score, 2)
            }
            
            return round(float(avg_similarity), 2), best_project_info
            
        except Exception as e:
            # print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Cosine Similarity: {e}")
            return 0.0, {}
    # -------------------------------------------------------------
    
    # -------------------------------------------------------------
    # 3. Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø¨ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ« (Ù…Ø¹Ø¯Ù„Ø© Ù„Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ø¬Ù„Ø¨ Ù…Ù† Google Scholar)
    # -------------------------------------------------------------
    async def _get_or_update_papers(self, supervisor: Dict) -> Tuple[Dict, List[Dict]]:
        """
        ØªÙØ¬Ù„Ø¨ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ù† SerpAPI (Google Scholar) ÙˆØªÙØ­Ø¯Ø«Ù‡Ø§ ÙÙŠ MongoDB Ù„Ù„Ø¹Ø±Ø¶.
        """
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª
        author_id = str(supervisor.get("Author_ID", "")).strip()
        orcid_id = str(supervisor.get("ORCID_ID", "")).strip() 

        
        
        search_id = None
        search_type = None

        if author_id:
            search_id = author_id
            search_type = "scholar_author_id"
        elif orcid_id: 
            search_id = orcid_id
            search_type = "orcid_id" 
        else:
            return supervisor, supervisor.get("recent_papers", [])

        # ğŸ’¡ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: ÙŠØªÙ… Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ø¬Ù„Ø¨ Ù…Ù† Google Scholar ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
        new_papers = []
        
        if search_type == "scholar_author_id" or search_type == "orcid_id":
            
            # print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù„Ù„Ø¯ÙƒØªÙˆØ± {supervisor.get('Name')} Ù…Ù† Google Scholar...")
            
            try:
                new_papers = await asyncio.to_thread(
                    scholar_lookup_service.search_scholar_by_author_id,
                    search_id, 
                    max_results=15
                )
            except Exception as e:
                # print(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø¯ÙƒØªÙˆØ± {supervisor.get('Name')}: {e}")
                pass

        if new_papers:
            # 4. ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ MongoDB Ø¨Ø¢Ø®Ø± Ø§Ù„Ø£Ø¨Ø­Ø§Ø«
            most_recent_paper_date = max(
                (p.get("year", 1900) for p in new_papers if p.get("year")), 
                default=datetime.datetime.now().year
            )
            
            last_updated_str = f"{most_recent_paper_date}-01-01" 

            # Ù†Ø­Ø¯Ø« MongoDB (Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©)
            self.supervisors_collection.update_one(
                {"_id": supervisor["_id"]},
                {
                    "$set": {
                        "recent_papers": new_papers,
                        "papers_count": len(new_papers),
                        "last_updated": last_updated_str 
                    }
                }
            )
            # Ù†Ø­Ø¯Ø« ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø´Ø±Ù Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
            supervisor["last_updated"] = last_updated_str
            return supervisor, new_papers
        
        # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨ØŒ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù…Ù„Ø§Ø° Ø£Ø®ÙŠØ±)
        return supervisor, supervisor.get("recent_papers", [])
    # -------------------------------------------------------------

    # -------------------------------------------------------------
    # 4. Ø¯Ø§Ù„Ø© ÙØ­Øµ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    # -------------------------------------------------------------
    def _check_department_similarity(self, dept1: str, dept2: str) -> bool:
        """ÙØ­Øµ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø±Ø§Ø¯ÙØ§Øª Ø¨Ø³ÙŠØ·Ø©."""
        synonyms = {
            "computer science": ["cs", "computing", "informatics", "it"],
            "information technology": ["it", "computer science", "computing"],
            "software engineering": ["cs", "computer science", "engineering"],
            "electrical engineering": ["ee", "electronics", "electrical"],
            "mechanical engineering": ["me", "mechanics"],
            "civil engineering": ["ce", "civil"],
            "information systems": ["is", "mis", "information technology"],
        }
        
        dept1 = dept1.lower().strip()
        dept2 = dept2.lower().strip()
        
        for key, values in synonyms.items():
            if (key in dept1 and dept2 in values) or (key in dept2 and dept1 in values):
                return True
            
        if ("computer" in dept1 and "computer" in dept2) or ("engineering" in dept1 and "engineering" in dept2):
            return True
            
        return False
    # -------------------------------------------------------------
    
    # -------------------------------------------------------------
    # 5. Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ù…Ø¹Ø¯Ù„Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø­Ø¯Ø§Ø«Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯)
    # -------------------------------------------------------------
    async def _score_supervisors(
        self, 
        supervisors: List[Dict], 
        idea_keywords: List[str],
        label: str,
        idea_embedding: List[float] 
    ) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©ØŒ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠØŒ ÙˆØ§Ù„Ø­Ø¯Ø§Ø«Ø©."""
        scored = []
        
        tasks_papers = []
        tasks_supervision_match = []
        for supervisor in supervisors:
            tasks_papers.append(self._get_or_update_papers(supervisor))
            tasks_supervision_match.append(self._calculate_supervision_match(str(supervisor.get("_id")), idea_embedding))
            
        papers_results = await asyncio.gather(*tasks_papers)
        supervision_match_results = await asyncio.gather(*tasks_supervision_match) 
        
        for idx, (supervisor, recent_papers) in enumerate(papers_results):
            name = supervisor.get("Name", "Unknown")
            
            supervision_match_score, best_matched_project = supervision_match_results[idx] 
            
            # ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø­Ø³Ø§Ø¨ current_load Ùˆ load_multiplier
            # current_load = supervisor.get("current_load", 0)
            # load_multiplier = 1.0 if current_load < MAX_SUPERVISOR_LOAD else 0.5 

            semantic_similarity = supervisor.get('qdrant_score', 0.0)
            
            if recent_papers and (supervisor.get("Author_ID") or supervisor.get("ORCID_ID")):
                
                # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙˆØ³Ø¹Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù„ØºÙˆÙŠ
                simple_keywords = set()
                for k in idea_keywords:
                    k_lower = k.lower()
                    simple_keywords.add(k_lower)
                    # ØªÙÙƒÙŠÙƒ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§ÙƒØªØ´Ø§Ù (ØªØµØ­ÙŠØ­ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù„ÙŠØ­ÙŠØ¯ÙŠ)
                    if 'deep learning' in k_lower: simple_keywords.add('deep learning')
                    if 'transportation' in k_lower: simple_keywords.add('transportation')
                    if 'anomaly detection' in k_lower: simple_keywords.add('anomaly')
                    if 'traffic analysis' in k_lower: simple_keywords.add('traffic')


                # 2. ØªØµÙÙŠØ© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø¨Ø­Ø«ÙŠØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„ÙÙƒØ±Ø©)
                relevant_matched_papers = [
                    p for p in recent_papers 
                    if p.get('title') and any(simple_k in p['title'].lower() or simple_k in p.get('abstract', '').lower() 
                                                 for simple_k in simple_keywords)
                ]
                
                # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÙŠØ® Ø£Ø­Ø¯Ø« ÙˆØ±Ù‚Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ù…Ø¬Ø§Ù„
                latest_relevant_date_str = "N/A"
                if relevant_matched_papers:
                    latest_year = max(p.get("year", 1900) for p in relevant_matched_papers if p.get("year"))
                    if latest_year > 1900:
                        latest_relevant_date_str = f"{latest_year}-01-01"

                # Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„ØªØ¨Ø±ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©)
                top_matched_papers = [p['title'] for p in relevant_matched_papers][:3]


                # ğŸ’¡ 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¯Ø§Ø«Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ„Ø© (Recency Score)
                recency_score = self._calculate_recency_score(latest_relevant_date_str) 
                
                # ğŸ’¡ 5. Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø£Ø¯Ù†Ù‰: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© ØµÙØ± (Ù„Ø¹Ø¯Ù… Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù„ØºÙˆÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±)ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø£Ø¯Ù†Ù‰ (0.50)
                if recency_score == 0.00 and latest_relevant_date_str == "N/A":
                    general_last_updated = supervisor.get("last_updated", "N/A") 
                    general_recency_score = self._calculate_recency_score(general_last_updated) 
                    
                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ®ÙÙŠØ¶ Ø¨Ù†Ø³Ø¨Ø© 50% ÙƒÙˆØ²Ù† Ø£Ø¯Ù†Ù‰
                    recency_score = round(general_recency_score * 0.5, 2)
                    
                semantic_weight = 0.50
                supervision_weight = 0.30
                recency_weight = 0.20
                
                final_score = (
                    semantic_similarity * semantic_weight + 
                    supervision_match_score * supervision_weight + 
                    recency_score * recency_weight 
                )
                
                # ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø³Ø·Ø± ØªØ·Ø¨ÙŠÙ‚ load_multiplier
                # final_score *= load_multiplier 
                
                print(f" Â  âœ… {name} Score: {final_score:.2f} (Case 1: Research, Semantic: {semantic_similarity:.2f} | Super: {supervision_match_score:.2f} | Recency: {recency_score:.2f})")
                
                
            elif not recent_papers and supervision_match_score > 0:
                
                semantic_interest = semantic_similarity
                
                final_score = (
                    semantic_interest * 0.50 + 
                    supervision_match_score * 0.50 
                )
                
                # ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø³Ø·Ø± ØªØ·Ø¨ÙŠÙ‚ load_multiplier
                # final_score *= load_multiplier 
                
                print(f" Â  ğŸ”¹ {name} Score: {final_score:.2f} (Case 2: Interest/Supervision, Semantic_Int: {semantic_interest:.2f} | Super: {supervision_match_score:.2f})")
                
                
            else: 
                
                semantic_interest = semantic_similarity
                
                final_score = semantic_interest * 0.80 
                
                # ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø³Ø·Ø± ØªØ·Ø¨ÙŠÙ‚ load_multiplier
                # final_score *= load_multiplier 
                
                print(f" Â  âŒ {name} Score: {final_score:.2f} (Case 3: Pure Interest, Semantic_Int: {semantic_similarity:.2f})")

            
            final_score = max(0.0, min(float(final_score), 1.0))
            
            
            if final_score > 0.15: 
                scored.append({
                    "supervisor": supervisor,
                    "similarity": final_score,
                    "recent_papers": recent_papers, 
                    "supervision_match_score": supervision_match_score, 
                    "final_score": final_score,
                    "semantic_similarity": semantic_similarity,
                    "top_matched_papers": top_matched_papers if 'top_matched_papers' in locals() else [],
                    "research_relevance": {"matched_keywords": simple_keywords if 'simple_keywords' in locals() else []},
                    "best_matched_project": best_matched_project
                })
        
        return scored
    # -------------------------------------------------------------

    # -------------------------------------------------------------
    # 6. Ø¯Ø§Ù„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ JSON)
    # -------------------------------------------------------------
    async def _rerank_and_explain(self, recommendations: List[Dict], idea_text: str) -> List[Dict]:
        """
        ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (Re-ranking) ÙˆØ§Ù„Ø´Ø±Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù„ØºØ© (Gemini).
        """
        if not recommendations:
            return []
            
        print("\nğŸ§  ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (Re-ranking) ÙˆØªÙˆÙ„ÙŠØ¯ Ø³Ø¨Ø¨ Ø§Ù„ØªØ±Ø´ÙŠØ­...")
        
        reranking_data = []
        for i, rec in enumerate(recommendations):
            
            best_project = rec.get("best_matched_project", {})
            
            reranking_data.append({
                "id": i,
                "name": rec["supervisor"].get("Name"),
                "department": rec["supervisor"].get("Department"),
                "initial_score": rec["final_score"],
                "semantic_similarity": rec["semantic_similarity"],
                "supervision_match_score": rec.get("supervision_match_score", 0.0), 
                # ğŸ’¡ Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ "set is not JSON serializable"
                "matching_keywords": list(rec.get("research_relevance", {}).get("matched_keywords", [])),
                "is_same_major": rec.get("is_same_major", False),
                "top_matched_papers": rec.get("top_matched_papers", []),
                "best_matched_project_title": best_project.get("title", ""), 
                "best_matched_project_score": best_project.get("match_score", 0.0) 
            })
            
        try:
            reranked_results = await gemini_service.get_reranked_recommendations(
                reranking_data=reranking_data,
                idea_text=idea_text 
            )
            
            if not isinstance(reranked_results, list) or not reranked_results:
                raise ValueError("Gemini returned invalid or empty Reranking results.")
            
            reranked_map = {item.get('id'): item for item in reranked_results}
            
            final_recommendations = []
            for rec in recommendations:
                original_id = rec["id"]
                rerank_info = reranked_map.get(original_id)
                
                if rerank_info:
                    rec["final_score"] = float(rerank_info.get("reranked_score", rec["final_score"]))
                    rec["justification"] = rerank_info.get("Justification", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ¨Ø±ÙŠØ± Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
                else:
                    rec["justification"] = "ØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†ØªÙŠØ¬Ø© Ø±ÙŠØ±Ù†ÙƒÙ†Ø¬." 
                
                final_recommendations.append(rec)

            final_recommendations.sort(key=lambda x: x["final_score"], reverse=True)
            
            print("âœ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø´Ø±Ø­ Ø¨Ù†Ø¬Ø§Ø­.")
            return final_recommendations
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Reranking: {e}. Ø³ÙŠØªÙ… Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙŠ.")
            
            recommendations.sort(key=lambda x: x["final_score"], reverse=True)
            
            for rec in recommendations:
                if 'justification' not in rec:
                    rec["justification"] = f"ØªÙ… Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {rec['final_score']:.2f} (ÙØ´Ù„ Ø§Ù„Ø±ÙŠØ±Ù†ÙƒÙ†Ø¬)."
                    
            return recommendations
    # -------------------------------------------------------------
    
    # -------------------------------------------------------------
    # 7. Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    # -------------------------------------------------------------
    async def recommend_supervisors(
        self, 
        idea_text: str, 
        student_major: str,
        top_k: int = 5
    ) -> List[Dict]:
        """
        ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†: Ø§Ø³ØªØ®Ø¯Ø§Ù… Qdrant Ù„Ù„ØªØ±Ø´ÙŠØ­ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø«Ù… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ.
        """
        
        # 0. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„ÙÙƒØ±Ø© Ø§Ù„Ø·Ø§Ù„Ø¨
        print("\n--- ğŸ§  Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ ÙÙƒØ±Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ (ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©) ---")
        # ğŸ’¡ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„ØªÙ†Ø§Ø³Ø¨ ÙÙƒØ±Ø© "Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø°ÙƒÙŠ" Ø¨Ø¯Ù‚Ø© Ø£ÙƒØ¨Ø±
        idea_keywords = ["Intelligent Transportation Systems", "Deep Learning", "Anomaly Detection", "Smart Cities", "Traffic Analysis", "Optimization", "Pedestrian Safety", "Computer Vision", "Machine Learning"] 
        idea_embedding = embedding_service.embed_text(idea_text)
        
        if not idea_embedding:
            print("âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡. Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ±Ø´ÙŠØ­.")
            return []
            
        print(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙƒØ±Ø©. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {', '.join(idea_keywords[:3])}...")
        
        # 1. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙÙŠ Qdrant 
        print(f"\n1. ğŸ—ƒï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙÙŠ Qdrant Ø¹Ù† Ø£ÙØ¶Ù„ {top_k * 4} Ù…Ø´Ø±Ù...")
        qdrant_matches = qdrant_service.search_supervisors_by_vector(
            query_vector=idea_embedding,
            top_k=top_k * 4
        )
        
        if not qdrant_matches:
            print("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø´Ø±ÙÙŠÙ† Ù…Ø·Ø§Ø¨Ù‚ÙŠÙ† ÙÙŠ Qdrant.")
            return []

        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ù† MongoDB 
        matched_mongo_ids = []
        for m in qdrant_matches:
            mongo_id_str = m.get('mongo_id')
            
            if mongo_id_str and isinstance(mongo_id_str, str) and len(mongo_id_str) == 24:
                try:
                    matched_mongo_ids.append(ObjectId(mongo_id_str))
                except Exception:
                    pass
        
        if not matched_mongo_ids:
            print("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø¹Ø±Ù‘ÙØ§Øª (IDs) ØµØ§Ù„Ø­Ø© Ù…Ù† Qdrant Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ MongoDB.")
            return []
        
        # print(f"ğŸ“Œ IDs ØµØ§Ù„Ø­Ø© Ù„Ù€ MongoDB: {matched_mongo_ids[:3]}...")
        
        all_supervisors = list(
            self.supervisors_collection.find(
                {"_id": {"$in": matched_mongo_ids}},
                max_time_ms=60000 
            )
        )
        
        if not all_supervisors:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø£ÙŠ Ù…Ø´Ø±ÙÙŠÙ† Ù…Ù† MongoDB. ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù€ IDs Ø¨ÙŠÙ† Qdrant Ùˆ MongoDB.")
            return []
        
        qdrant_scores_map = {str(m.get('mongo_id')): m.get('similarity_score', 0.0) 
                             for m in qdrant_matches 
                             if m.get('mongo_id') and len(str(m.get('mongo_id'))) == 24}
        
        for sup in all_supervisors:
            sup['qdrant_score'] = qdrant_scores_map.get(str(sup['_id']), 0.0) 
        
        print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(all_supervisors)} Ù…Ø´Ø±Ù Ù„Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙØµÙŠÙ„ÙŠ.")
        
        # 3. ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†
        same_major = []
        different_major = []
        
        for supervisor in all_supervisors:
            dept = str(supervisor.get("Department", "")).lower()
            major_lower = student_major.lower()
            
            is_same = (
                major_lower in dept or 
                dept in major_lower or
                self._check_department_similarity(dept, major_lower) 
            )
            
            if is_same:
                same_major.append(supervisor)
            else:
                different_major.append(supervisor)
        
        print(f"ğŸ“Š ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ† (Ø¨Ø¹Ø¯ Qdrant):")
        print(f" Â  âœ… Ù†ÙØ³ Ø§Ù„ØªØ®ØµØµ: {len(same_major)}")
        print(f" Â  ğŸ”¹ Ø®Ø§Ø±Ø¬ Ø§Ù„ØªØ®ØµØµ: {len(different_major)}\n")
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ† ÙˆØªØ·Ø¨ÙŠÙ‚ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        print("ğŸ” ØªØ·Ø¨ÙŠÙ‚ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ÙˆØ²ÙˆÙ†...")
        
        idea_embedding_list = idea_embedding.tolist() if isinstance(idea_embedding, np.ndarray) else idea_embedding
        
        # ğŸ’¡ ÙŠØªÙ… ØªØ¬Ù…ÙŠØ¹ Ù…Ù‡Ø§Ù… Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« ÙˆØ§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠ Ø¯Ø§Ø®Ù„ _score_supervisors
        same_major_scored = await self._score_supervisors(
            supervisors=same_major, 
            idea_keywords=idea_keywords, 
            label="Ù†ÙØ³ Ø§Ù„ØªØ®ØµØµ",
            idea_embedding=idea_embedding_list
        )
        
        different_major_scored = await self._score_supervisors(
            supervisors=different_major, 
            idea_keywords=idea_keywords, 
            label="Ø®Ø§Ø±Ø¬ Ø§Ù„ØªØ®ØµØµ",
            idea_embedding=idea_embedding_list
        )
        
        # 5. ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØªØ·Ø¨ÙŠÙ‚ Ù‚Ø§Ø¹Ø¯Ø© 3+2
        same_major_scored.sort(key=lambda x: x["final_score"], reverse=True)
        different_major_scored.sort(key=lambda x: x["final_score"], reverse=True)
        
        recommendations = []
        
        recommendations.extend(same_major_scored[:3])
        recommendations.extend(different_major_scored[:2])
        
        # 6. Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ®ØµØµ
        for i, rec in enumerate(recommendations):
            dept = str(rec["supervisor"].get("Department", "")).lower()
            is_same_major = (student_major.lower() in dept or 
                             dept in student_major.lower() or 
                             self._check_department_similarity(dept, student_major.lower()))
            rec["is_same_major"] = is_same_major
            rec["id"] = i 
            
        # 7. ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (Re-ranking) ÙˆØªÙˆÙ„ÙŠØ¯ Ø³Ø¨Ø¨ Ø§Ù„ØªØ±Ø´ÙŠØ­ 
        recommendations = await self._rerank_and_explain(recommendations, idea_text)
        
        print(f"\n{'='*80}")
        print("ğŸ† Recommended Supervisors Analytical Report (Weighted Scores)")
        print(f"{'='*80}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø£ÙØ¶Ù„ Ø¹Ø¯Ø¯ (top_k) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©
        for i, rec in enumerate(recommendations[:top_k]):
            name = rec["supervisor"].get("Name", "Unknown")
            is_same_major = "âœ…  Same Major" if rec.get("is_same_major") else "ğŸ”¹ Outside Major"
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„ÙƒÙ…ÙŠØ©)
            semantic_score = rec.get("semantic_similarity", 0.0) 
            supervision_score = rec.get("supervision_match_score", 0.0) 
            initial_score = rec.get("initial_score", rec["final_score"]) 
            
            print(f"ğŸ¥‡ Candidate #{i+1}: {name} ({is_same_major})")
            print(f"   Final Score (After Reranking): {rec['final_score']:.2f}")
            
            # ************************************************************
            # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ©
            # ************************************************************
            print(f" ğŸ“Š Initial Quantitative Analysis: :")
            print(f"      - Semantic Similarity: tic Similarity): {semantic_score:.2f} (Weight 50%)")
            print(f"      - Supervision Match: (Supervision Match): {supervision_score:.2f} (Weight 30%)")
            # Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù€ Recency Score Ù…Ø¨Ø§Ø´Ø±Ø© Ù‡Ù†Ø§ØŒ Ù„ÙƒÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ØªØ´Ù…Ù„Ù‡Ø§
            print(f"      - Initial Weighted Score (Pre-Rerank): {initial_score:.2f}") 
            
            
            # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ù„Ù‡ Ù„ÙŠÙƒÙˆÙ† Ø¯Ø§Ø®Ù„ Ø­Ù„Ù‚Ø© for
            print(f"{'-'*80}") 


        print(f"\nâœ… ØªÙ… Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ…ÙŠ Ù„Ù„Ù€ {top_k} Ù…Ø´Ø±Ù Ø§Ù„Ø£ÙØ¶Ù„.")
        print(f"{'='*80}\n")
        
        return recommendations[:top_k]
        
    # -------------------------------------------------------------

# ğŸ›‘ ÙŠØ¬Ø¨ Ø¥Ø¨Ù‚Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„ÙƒÙ„Ø§Ø³ Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙƒØ§Ø¦Ù†
supervisor_recommendation = SupervisorRecommendation()